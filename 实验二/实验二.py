import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_validate, KFold, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, \
    confusion_matrix
from sklearn.preprocessing import StandardScaler
import warnings

warnings.filterwarnings('ignore')


class LogisticRegressionExperiment:
    """é€»è¾‘å›å½’ç®—æ³•å®ç°ä¸æµ‹è¯•å®éªŒ"""

    def __init__(self, random_state=42):
        self.random_state = random_state
        self.X = None
        self.y = None
        self.feature_names = None
        self.target_names = None
        self.df = None
        self.model = None
        self.cv_results = None

    def load_and_analyze_iris(self):
        """
        (1) ä»scikit-learnåº“åŠ è½½irisæ•°æ®é›†å¹¶è¿›è¡Œæ•°æ®åˆ†æ
        """
        print("=" * 60)
        print("æ­¥éª¤1: Irisæ•°æ®é›†åŠ è½½ä¸æ•°æ®åˆ†æ")
        print("=" * 60)

        # åŠ è½½æ•°æ®é›†
        iris = load_iris()
        self.X = iris.data
        self.y = iris.target
        self.feature_names = iris.feature_names
        self.target_names = iris.target_names

        print("æ•°æ®é›†åŠ è½½æˆåŠŸ!")
        print(f"ç‰¹å¾æ•°æ®å½¢çŠ¶: {self.X.shape}")
        print(f"ç›®æ ‡å˜é‡å½¢çŠ¶: {self.y.shape}")
        print(f"ç‰¹å¾åç§°: {self.feature_names}")
        print(f"ç›®æ ‡ç±»åˆ«: {list(self.target_names)}")
        print(f"æ ·æœ¬åˆ†å¸ƒ: {np.bincount(self.y)} - {list(self.target_names)}")

        # åˆ›å»ºDataFrameç”¨äºæ•°æ®åˆ†æ
        self.df = pd.DataFrame(self.X, columns=self.feature_names)
        self.df['target'] = self.y
        self.df['class'] = self.df['target'].map({i: name for i, name in enumerate(self.target_names)})

        # åŸºæœ¬ç»Ÿè®¡åˆ†æ
        print("\næ•°æ®é›†å‰5è¡Œ:")
        print(self.df.head())

        print("\næ•°æ®é›†åŸºæœ¬ä¿¡æ¯:")
        print(self.df.describe())

        # æ•°æ®å¯è§†åŒ–åˆ†æ
        self._visualize_data()

        return self.X, self.y, self.feature_names, self.target_names, self.df

    def _visualize_data(self):
        """æ•°æ®å¯è§†åŒ–åˆ†æ"""
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # ç‰¹å¾åˆ†å¸ƒç›´æ–¹å›¾
        for i, feature in enumerate(self.feature_names):
            row, col = i // 2, i % 2
            for target_class in range(3):
                data = self.df[self.df['target'] == target_class][feature]
                axes[row, col].hist(data, alpha=0.7, label=self.target_names[target_class])
            axes[row, col].set_title(f'{feature}åˆ†å¸ƒ')
            axes[row, col].legend()
            axes[row, col].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.show()

        # æ•£ç‚¹çŸ©é˜µå›¾
        plt.figure(figsize=(12, 10))
        scatter_matrix = pd.plotting.scatter_matrix(
            self.df[self.feature_names],
            c=self.df['target'],
            figsize=(12, 10),
            marker='o',
            alpha=0.8,
            cmap='viridis'
        )
        plt.suptitle('ç‰¹å¾æ•£ç‚¹çŸ©é˜µå›¾', y=0.95, fontsize=16)
        plt.show()

    def five_fold_cross_validation(self):
        """
        (2) äº”æŠ˜äº¤å‰éªŒè¯è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤2: äº”æŠ˜äº¤å‰éªŒè¯è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹")
        print("=" * 60)

        # åˆ›å»ºé€»è¾‘å›å½’æ¨¡å‹ï¼ˆå¯¹æ•°å‡ ç‡å›å½’ï¼‰
        self.model = LogisticRegression(
            random_state=self.random_state,
            max_iter=1000,  # ç¡®ä¿æ”¶æ•›
            multi_class='multinomial',  # å¤šåˆ†ç±»é—®é¢˜
            solver='lbfgs'  # é€‚ç”¨äºå¤šåˆ†ç±»çš„ä¼˜åŒ–ç®—æ³•
        )

        # å®šä¹‰äº”æŠ˜äº¤å‰éªŒè¯
        kf = KFold(n_splits=5, shuffle=True, random_state=self.random_state)

        # å®šä¹‰è¯„ä¼°æŒ‡æ ‡
        scoring = {
            'accuracy': 'accuracy',
            'precision_macro': 'precision_macro',
            'recall_macro': 'recall_macro',
            'f1_macro': 'f1_macro'
        }

        # æ‰§è¡Œäº¤å‰éªŒè¯
        self.cv_results = cross_validate(
            self.model, self.X, self.y,
            cv=kf,
            scoring=scoring,
            return_train_score=True,
            return_estimator=True
        )

        print("äº”æŠ˜äº¤å‰éªŒè¯å®Œæˆ!")
        return self.cv_results, self.model

    def evaluate_model_performance(self):
        """
        (3) ä½¿ç”¨äº”æŠ˜äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹æ€§èƒ½
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤3: æ¨¡å‹æ€§èƒ½è¯„ä¼°ï¼ˆäº”æŠ˜äº¤å‰éªŒè¯ç»“æœï¼‰")
        print("=" * 60)

        # æ‰“å°è¯¦ç»†çš„äº¤å‰éªŒè¯ç»“æœ
        self._print_cross_validation_results()

        # ç‹¬ç«‹æµ‹è¯•é›†éªŒè¯
        self._independent_test_set_validation()

        # æ¨¡å‹ç³»æ•°åˆ†æ
        self._analyze_model_coefficients()

    def _print_cross_validation_results(self):
        """æ‰“å°äº¤å‰éªŒè¯è¯¦ç»†ç»“æœ"""
        print("\näº”æŠ˜äº¤å‰éªŒè¯ç»Ÿè®¡ç»“æœï¼ˆå‡å€¼ Â± æ ‡å‡†å·®ï¼‰:")
        print("-" * 50)

        metrics = {
            'è®­ç»ƒå‡†ç¡®åº¦': ('train_accuracy', 'äº¤å‰éªŒè¯è®­ç»ƒé›†å‡†ç¡®åº¦'),
            'æµ‹è¯•å‡†ç¡®åº¦': ('test_accuracy', 'äº¤å‰éªŒè¯æµ‹è¯•é›†å‡†ç¡®åº¦'),
            'æµ‹è¯•ç²¾åº¦': ('test_precision_macro', 'å®å¹³å‡ç²¾åº¦'),
            'æµ‹è¯•å¬å›ç‡': ('test_recall_macro', 'å®å¹³å‡å¬å›ç‡'),
            'æµ‹è¯•F1å€¼': ('test_f1_macro', 'å®å¹³å‡F1åˆ†æ•°')
        }

        for name, (key, desc) in metrics.items():
            mean_val = np.mean(self.cv_results[key])
            std_val = np.std(self.cv_results[key])
            print(f"{name}: {mean_val:.4f} (Â±{std_val:.4f}) - {desc}")

        # å„æŠ˜è¯¦ç»†ç»“æœ
        print("\nå„æŠ˜è¯¦ç»†ç»“æœ:")
        print("æŠ˜å·\tè®­ç»ƒå‡†ç¡®åº¦\tæµ‹è¯•å‡†ç¡®åº¦\tæµ‹è¯•ç²¾åº¦\tæµ‹è¯•å¬å›ç‡\tæµ‹è¯•F1å€¼")
        print("-" * 80)
        for i in range(5):
            print(f"{i + 1}\t"
                  f"{self.cv_results['train_accuracy'][i]:.4f}\t\t"
                  f"{self.cv_results['test_accuracy'][i]:.4f}\t\t"
                  f"{self.cv_results['test_precision_macro'][i]:.4f}\t\t"
                  f"{self.cv_results['test_recall_macro'][i]:.4f}\t\t"
                  f"{self.cv_results['test_f1_macro'][i]:.4f}")

    def _independent_test_set_validation(self):
        """ç‹¬ç«‹æµ‹è¯•é›†éªŒè¯"""
        print("\n" + "-" * 50)
        print("ç‹¬ç«‹æµ‹è¯•é›†éªŒè¯ç»“æœ")
        print("-" * 50)

        # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y, test_size=0.3, random_state=self.random_state, stratify=self.y
        )

        # è®­ç»ƒæ¨¡å‹
        model = LogisticRegression(random_state=self.random_state, max_iter=1000, multi_class='multinomial')
        model.fit(X_train, y_train)

        # é¢„æµ‹
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, average='macro')
        recall = recall_score(y_test, y_pred, average='macro')
        f1 = f1_score(y_test, y_pred, average='macro')

        print(f"å‡†ç¡®åº¦ (Accuracy): {accuracy:.4f}")
        print(f"ç²¾åº¦ (Precision-macro): {precision:.4f}")
        print(f"å¬å›ç‡ (Recall-macro): {recall:.4f}")
        print(f"F1å€¼ (F1-macro): {f1:.4f}")

        # å„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡
        print("\nå„ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:")
        precision_per_class = precision_score(y_test, y_pred, average=None)
        recall_per_class = recall_score(y_test, y_pred, average=None)
        f1_per_class = f1_score(y_test, y_pred, average=None)

        print("ç±»åˆ«\t\tç²¾åº¦\t\tå¬å›ç‡\t\tF1å€¼")
        print("-" * 45)
        for i, class_name in enumerate(self.target_names):
            print(f"{class_name:<12}\t{precision_per_class[i]:.4f}\t\t"
                  f"{recall_per_class[i]:.4f}\t\t{f1_per_class[i]:.4f}")

        # æ··æ·†çŸ©é˜µ
        self._plot_confusion_matrix(y_test, y_pred)

        # åˆ†ç±»æŠ¥å‘Š
        print(f"\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test, y_pred, target_names=self.target_names))

    def _plot_confusion_matrix(self, y_true, y_pred):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        cm = confusion_matrix(y_true, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=self.target_names, yticklabels=self.target_names)
        plt.title('æ··æ·†çŸ©é˜µ')
        plt.xlabel('é¢„æµ‹æ ‡ç­¾')
        plt.ylabel('çœŸå®æ ‡ç­¾')
        plt.show()

    def _analyze_model_coefficients(self):
        """åˆ†ææ¨¡å‹ç³»æ•°ï¼ˆç‰¹å¾é‡è¦æ€§ï¼‰"""
        print("\n" + "-" * 50)
        print("é€»è¾‘å›å½’æ¨¡å‹ç³»æ•°åˆ†æ")
        print("-" * 50)

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæŠ˜çš„æ¨¡å‹è¿›è¡Œåˆ†æ
        model = self.cv_results['estimator'][0]

        # å¤šåˆ†ç±»é—®é¢˜çš„ç³»æ•°çŸ©é˜µ
        coefficients = model.coef_
        intercepts = model.intercept_

        print("å„ç±»åˆ«çš„ç‰¹å¾ç³»æ•°:")
        print("ç‰¹å¾\t\t" + "\t".join(self.target_names))
        print("-" * 50)
        for i, feature in enumerate(self.feature_names):
            coef_str = "\t\t".join([f"{coef:.4f}" for coef in coefficients[:, i]])
            print(f"{feature:<15}\t{coef_str}")

        print(f"\næˆªè·é¡¹: {intercepts}")

        # ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
        self._plot_feature_importance(coefficients)

    def _plot_feature_importance(self, coefficients):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        # è®¡ç®—ç‰¹å¾é‡è¦æ€§ï¼ˆç³»æ•°ç»å¯¹å€¼å‡å€¼ï¼‰
        importance = np.mean(np.abs(coefficients), axis=0)

        plt.figure(figsize=(10, 6))
        bars = plt.barh(self.feature_names, importance)
        plt.xlabel('ç‰¹å¾ç³»æ•°ç»å¯¹å€¼ï¼ˆé‡è¦æ€§ï¼‰')
        plt.title('é€»è¾‘å›å½’ç‰¹å¾é‡è¦æ€§åˆ†æ')
        plt.gca().invert_yaxis()

        # åœ¨æ¡å½¢ä¸Šæ·»åŠ æ•°å€¼
        for bar, imp in zip(bars, importance):
            plt.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height() / 2,
                     f'{imp:.4f}', ha='left', va='center')

        plt.tight_layout()
        plt.show()

    def performance_comparison_analysis(self):
        """
        (4) æ€§èƒ½æ¯”è¾ƒåˆ†æ
        """
        print("\n" + "=" * 60)
        print("æ­¥éª¤4: æ¨¡å‹æ€§èƒ½æ¯”è¾ƒåˆ†æ")
        print("=" * 60)

        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        avg_accuracy = np.mean(self.cv_results['test_accuracy'])
        avg_precision = np.mean(self.cv_results['test_precision_macro'])
        avg_recall = np.mean(self.cv_results['test_recall_macro'])
        avg_f1 = np.mean(self.cv_results['test_f1_macro'])

        # æ€§èƒ½åˆ†æ
        print("æ€§èƒ½åˆ†ææ€»ç»“:")
        print(f"âœ… å¹³å‡å‡†ç¡®åº¦: {avg_accuracy:.4f}")
        print(f"âœ… å¹³å‡ç²¾åº¦: {avg_precision:.4f}")
        print(f"âœ… å¹³å‡å¬å›ç‡: {avg_recall:.4f}")
        print(f"âœ… å¹³å‡F1åˆ†æ•°: {avg_f1:.4f}")

        # ç¨³å®šæ€§åˆ†æï¼ˆæ ‡å‡†å·®ï¼‰
        std_accuracy = np.std(self.cv_results['test_accuracy'])
        print(f"ğŸ“Š å‡†ç¡®åº¦ç¨³å®šæ€§ï¼ˆæ ‡å‡†å·®ï¼‰: {std_accuracy:.4f}")

        # æ€§èƒ½è¯„ä¼°
        if avg_accuracy > 0.95:
            rating = "ä¼˜ç§€"
        elif avg_accuracy > 0.90:
            rating = "è‰¯å¥½"
        elif avg_accuracy > 0.85:
            rating = "ä¸€èˆ¬"
        else:
            rating = "éœ€è¦æ”¹è¿›"

        print(f"ğŸ“ˆ æ¨¡å‹æ€§èƒ½è¯„çº§: {rating}")

        # è¿‡æ‹Ÿåˆåˆ†æ
        train_accuracy = np.mean(self.cv_results['train_accuracy'])
        overfitting_gap = train_accuracy - avg_accuracy
        print(f"ğŸ” è¿‡æ‹Ÿåˆç¨‹åº¦ï¼ˆè®­ç»ƒ-æµ‹è¯•å·®è·ï¼‰: {overfitting_gap:.4f}")

        if overfitting_gap < 0.02:
            print("âœ… æ¨¡å‹æ³›åŒ–èƒ½åŠ›è‰¯å¥½ï¼Œè¿‡æ‹Ÿåˆç¨‹åº¦è¾ƒä½")
        elif overfitting_gap < 0.05:
            print("âš ï¸  å­˜åœ¨è½»å¾®è¿‡æ‹Ÿåˆ")
        else:
            print("âŒ è¿‡æ‹Ÿåˆè¾ƒæ˜æ˜¾ï¼Œéœ€è¦è€ƒè™‘æ­£åˆ™åŒ–")

    def run_complete_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        print("=" * 70)
        print("ä¸Šæœºå®éªŒäºŒï¼šé€»è¾‘å›å½’ç®—æ³•å®ç°ä¸æµ‹è¯•")
        print("=" * 70)

        # (1) æ•°æ®åŠ è½½ä¸åˆ†æ
        self.load_and_analyze_iris()

        # (2) äº”æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ
        self.five_fold_cross_validation()

        # (3) æ¨¡å‹æ€§èƒ½è¯„ä¼°
        self.evaluate_model_performance()

        # (4) æ€§èƒ½æ¯”è¾ƒåˆ†æ
        self.performance_comparison_analysis()

        print("\n" + "=" * 70)
        print("å®éªŒå®Œæˆï¼")
        print("=" * 70)


# è¿è¡Œå®éªŒ
if __name__ == "__main__":
    experiment = LogisticRegressionExperiment(random_state=42)
    experiment.run_complete_experiment()